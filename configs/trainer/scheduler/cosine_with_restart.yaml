# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html
name: CosineAnnealingWarmRestarts
parameter:
  T_0: 10 # Number of iterations for the first restart.
  T_mult: 2 # A factor increases Ti after a restart. Default: 1
  eta_min: 0 # Minimum learning rate. Default: 0.
